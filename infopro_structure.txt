Module Name: , Module: VisionTransformer_front(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (criterion_ce): CrossEntropyLoss()
  (blocks): ModuleList(
    (0): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (1): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (aux_classifiers): ModuleList(
    (0): AuxClassifier(
      (criterion): CrossEntropyLoss()
      (aug): Sequential(
        (0): Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (loss_function): CrossEntropyLoss()
      (head): Linear(in_features=768, out_features=10, bias=True)
      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (pre_logits): Identity()
    )
    (1): AuxClassifier(
      (criterion): CrossEntropyLoss()
      (aug): Sequential(
        (0): Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (loss_function): CrossEntropyLoss()
      (head): Linear(in_features=768, out_features=10, bias=True)
      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (pre_logits): Identity()
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (pre_logits): Identity()
  (head): Linear(in_features=768, out_features=10, bias=True)
)
Module Name: patch_embed, Module: PatchEmbed(
  (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
  (norm): Identity()
)
Module Name: patch_embed.proj, Module: Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
Module Name: patch_embed.norm, Module: Identity()
Module Name: pos_drop, Module: Dropout(p=0.0, inplace=False)
Module Name: criterion_ce, Module: CrossEntropyLoss()
Module Name: blocks, Module: ModuleList(
  (0): Block(
    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=768, out_features=2304, bias=True)
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=768, out_features=768, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (drop_path): Identity()
    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=768, out_features=3072, bias=True)
      (act): GELU()
      (fc2): Linear(in_features=3072, out_features=768, bias=True)
      (drop): Dropout(p=0.0, inplace=False)
    )
  )
  (1): Block(
    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=768, out_features=2304, bias=True)
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=768, out_features=768, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (drop_path): Identity()
    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=768, out_features=3072, bias=True)
      (act): GELU()
      (fc2): Linear(in_features=3072, out_features=768, bias=True)
      (drop): Dropout(p=0.0, inplace=False)
    )
  )
)
Module Name: blocks.0, Module: Block(
  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=768, out_features=2304, bias=True)
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=768, out_features=768, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (drop_path): Identity()
  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=768, out_features=3072, bias=True)
    (act): GELU()
    (fc2): Linear(in_features=3072, out_features=768, bias=True)
    (drop): Dropout(p=0.0, inplace=False)
  )
)
Module Name: blocks.0.norm1, Module: LayerNorm((768,), eps=1e-06, elementwise_affine=True)
Module Name: blocks.0.attn, Module: Attention(
  (qkv): Linear(in_features=768, out_features=2304, bias=True)
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=768, out_features=768, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
Module Name: blocks.0.attn.qkv, Module: Linear(in_features=768, out_features=2304, bias=True)
Module Name: blocks.0.attn.attn_drop, Module: Dropout(p=0.0, inplace=False)
Module Name: blocks.0.attn.proj, Module: Linear(in_features=768, out_features=768, bias=True)
Module Name: blocks.0.attn.proj_drop, Module: Dropout(p=0.0, inplace=False)
Module Name: blocks.0.drop_path, Module: Identity()
Module Name: blocks.0.norm2, Module: LayerNorm((768,), eps=1e-06, elementwise_affine=True)
Module Name: blocks.0.mlp, Module: Mlp(
  (fc1): Linear(in_features=768, out_features=3072, bias=True)
  (act): GELU()
  (fc2): Linear(in_features=3072, out_features=768, bias=True)
  (drop): Dropout(p=0.0, inplace=False)
)
Module Name: blocks.0.mlp.fc1, Module: Linear(in_features=768, out_features=3072, bias=True)
Module Name: blocks.0.mlp.act, Module: GELU()
Module Name: blocks.0.mlp.fc2, Module: Linear(in_features=3072, out_features=768, bias=True)
Module Name: blocks.0.mlp.drop, Module: Dropout(p=0.0, inplace=False)
Module Name: blocks.1, Module: Block(
  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=768, out_features=2304, bias=True)
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=768, out_features=768, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (drop_path): Identity()
  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=768, out_features=3072, bias=True)
    (act): GELU()
    (fc2): Linear(in_features=3072, out_features=768, bias=True)
    (drop): Dropout(p=0.0, inplace=False)
  )
)
Module Name: blocks.1.norm1, Module: LayerNorm((768,), eps=1e-06, elementwise_affine=True)
Module Name: blocks.1.attn, Module: Attention(
  (qkv): Linear(in_features=768, out_features=2304, bias=True)
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=768, out_features=768, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
Module Name: blocks.1.attn.qkv, Module: Linear(in_features=768, out_features=2304, bias=True)
Module Name: blocks.1.attn.attn_drop, Module: Dropout(p=0.0, inplace=False)
Module Name: blocks.1.attn.proj, Module: Linear(in_features=768, out_features=768, bias=True)
Module Name: blocks.1.attn.proj_drop, Module: Dropout(p=0.0, inplace=False)
Module Name: blocks.1.drop_path, Module: Identity()
Module Name: blocks.1.norm2, Module: LayerNorm((768,), eps=1e-06, elementwise_affine=True)
Module Name: blocks.1.mlp, Module: Mlp(
  (fc1): Linear(in_features=768, out_features=3072, bias=True)
  (act): GELU()
  (fc2): Linear(in_features=3072, out_features=768, bias=True)
  (drop): Dropout(p=0.0, inplace=False)
)
Module Name: blocks.1.mlp.fc1, Module: Linear(in_features=768, out_features=3072, bias=True)
Module Name: blocks.1.mlp.act, Module: GELU()
Module Name: blocks.1.mlp.fc2, Module: Linear(in_features=3072, out_features=768, bias=True)
Module Name: blocks.1.mlp.drop, Module: Dropout(p=0.0, inplace=False)
Module Name: aux_classifiers, Module: ModuleList(
  (0): AuxClassifier(
    (criterion): CrossEntropyLoss()
    (aug): Sequential(
      (0): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (loss_function): CrossEntropyLoss()
    (head): Linear(in_features=768, out_features=10, bias=True)
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (pre_logits): Identity()
  )
  (1): AuxClassifier(
    (criterion): CrossEntropyLoss()
    (aug): Sequential(
      (0): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (loss_function): CrossEntropyLoss()
    (head): Linear(in_features=768, out_features=10, bias=True)
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (pre_logits): Identity()
  )
)
Module Name: aux_classifiers.0, Module: AuxClassifier(
  (criterion): CrossEntropyLoss()
  (aug): Sequential(
    (0): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (1): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (loss_function): CrossEntropyLoss()
  (head): Linear(in_features=768, out_features=10, bias=True)
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (pre_logits): Identity()
)
Module Name: aux_classifiers.0.criterion, Module: CrossEntropyLoss()
Module Name: aux_classifiers.0.aug, Module: Sequential(
  (0): Block(
    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=768, out_features=2304, bias=True)
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=768, out_features=768, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (drop_path): Identity()
    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=768, out_features=3072, bias=True)
      (act): GELU()
      (fc2): Linear(in_features=3072, out_features=768, bias=True)
      (drop): Dropout(p=0.0, inplace=False)
    )
  )
  (1): Block(
    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=768, out_features=2304, bias=True)
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=768, out_features=768, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (drop_path): Identity()
    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=768, out_features=3072, bias=True)
      (act): GELU()
      (fc2): Linear(in_features=3072, out_features=768, bias=True)
      (drop): Dropout(p=0.0, inplace=False)
    )
  )
)
Module Name: aux_classifiers.0.aug.0, Module: Block(
  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=768, out_features=2304, bias=True)
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=768, out_features=768, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (drop_path): Identity()
  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=768, out_features=3072, bias=True)
    (act): GELU()
    (fc2): Linear(in_features=3072, out_features=768, bias=True)
    (drop): Dropout(p=0.0, inplace=False)
  )
)
Module Name: aux_classifiers.0.aug.0.norm1, Module: LayerNorm((768,), eps=1e-06, elementwise_affine=True)
Module Name: aux_classifiers.0.aug.0.attn, Module: Attention(
  (qkv): Linear(in_features=768, out_features=2304, bias=True)
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=768, out_features=768, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
Module Name: aux_classifiers.0.aug.0.attn.qkv, Module: Linear(in_features=768, out_features=2304, bias=True)
Module Name: aux_classifiers.0.aug.0.attn.attn_drop, Module: Dropout(p=0.0, inplace=False)
Module Name: aux_classifiers.0.aug.0.attn.proj, Module: Linear(in_features=768, out_features=768, bias=True)
Module Name: aux_classifiers.0.aug.0.attn.proj_drop, Module: Dropout(p=0.0, inplace=False)
Module Name: aux_classifiers.0.aug.0.drop_path, Module: Identity()
Module Name: aux_classifiers.0.aug.0.norm2, Module: LayerNorm((768,), eps=1e-06, elementwise_affine=True)
Module Name: aux_classifiers.0.aug.0.mlp, Module: Mlp(
  (fc1): Linear(in_features=768, out_features=3072, bias=True)
  (act): GELU()
  (fc2): Linear(in_features=3072, out_features=768, bias=True)
  (drop): Dropout(p=0.0, inplace=False)
)
Module Name: aux_classifiers.0.aug.0.mlp.fc1, Module: Linear(in_features=768, out_features=3072, bias=True)
Module Name: aux_classifiers.0.aug.0.mlp.act, Module: GELU()
Module Name: aux_classifiers.0.aug.0.mlp.fc2, Module: Linear(in_features=3072, out_features=768, bias=True)
Module Name: aux_classifiers.0.aug.0.mlp.drop, Module: Dropout(p=0.0, inplace=False)
Module Name: aux_classifiers.0.aug.1, Module: Block(
  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=768, out_features=2304, bias=True)
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=768, out_features=768, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (drop_path): Identity()
  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=768, out_features=3072, bias=True)
    (act): GELU()
    (fc2): Linear(in_features=3072, out_features=768, bias=True)
    (drop): Dropout(p=0.0, inplace=False)
  )
)
Module Name: aux_classifiers.0.aug.1.norm1, Module: LayerNorm((768,), eps=1e-06, elementwise_affine=True)
Module Name: aux_classifiers.0.aug.1.attn, Module: Attention(
  (qkv): Linear(in_features=768, out_features=2304, bias=True)
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=768, out_features=768, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
Module Name: aux_classifiers.0.aug.1.attn.qkv, Module: Linear(in_features=768, out_features=2304, bias=True)
Module Name: aux_classifiers.0.aug.1.attn.attn_drop, Module: Dropout(p=0.0, inplace=False)
Module Name: aux_classifiers.0.aug.1.attn.proj, Module: Linear(in_features=768, out_features=768, bias=True)
Module Name: aux_classifiers.0.aug.1.attn.proj_drop, Module: Dropout(p=0.0, inplace=False)
Module Name: aux_classifiers.0.aug.1.drop_path, Module: Identity()
Module Name: aux_classifiers.0.aug.1.norm2, Module: LayerNorm((768,), eps=1e-06, elementwise_affine=True)
Module Name: aux_classifiers.0.aug.1.mlp, Module: Mlp(
  (fc1): Linear(in_features=768, out_features=3072, bias=True)
  (act): GELU()
  (fc2): Linear(in_features=3072, out_features=768, bias=True)
  (drop): Dropout(p=0.0, inplace=False)
)
Module Name: aux_classifiers.0.aug.1.mlp.fc1, Module: Linear(in_features=768, out_features=3072, bias=True)
Module Name: aux_classifiers.0.aug.1.mlp.act, Module: GELU()
Module Name: aux_classifiers.0.aug.1.mlp.fc2, Module: Linear(in_features=3072, out_features=768, bias=True)
Module Name: aux_classifiers.0.aug.1.mlp.drop, Module: Dropout(p=0.0, inplace=False)
Module Name: aux_classifiers.0.loss_function, Module: CrossEntropyLoss()
Module Name: aux_classifiers.0.head, Module: Linear(in_features=768, out_features=10, bias=True)
Module Name: aux_classifiers.0.norm, Module: LayerNorm((768,), eps=1e-06, elementwise_affine=True)
Module Name: aux_classifiers.0.pre_logits, Module: Identity()
Module Name: aux_classifiers.1, Module: AuxClassifier(
  (criterion): CrossEntropyLoss()
  (aug): Sequential(
    (0): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (1): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (loss_function): CrossEntropyLoss()
  (head): Linear(in_features=768, out_features=10, bias=True)
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (pre_logits): Identity()
)
Module Name: aux_classifiers.1.criterion, Module: CrossEntropyLoss()
Module Name: aux_classifiers.1.aug, Module: Sequential(
  (0): Block(
    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=768, out_features=2304, bias=True)
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=768, out_features=768, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (drop_path): Identity()
    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=768, out_features=3072, bias=True)
      (act): GELU()
      (fc2): Linear(in_features=3072, out_features=768, bias=True)
      (drop): Dropout(p=0.0, inplace=False)
    )
  )
  (1): Block(
    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=768, out_features=2304, bias=True)
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=768, out_features=768, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (drop_path): Identity()
    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=768, out_features=3072, bias=True)
      (act): GELU()
      (fc2): Linear(in_features=3072, out_features=768, bias=True)
      (drop): Dropout(p=0.0, inplace=False)
    )
  )
)
Module Name: aux_classifiers.1.aug.0, Module: Block(
  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=768, out_features=2304, bias=True)
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=768, out_features=768, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (drop_path): Identity()
  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=768, out_features=3072, bias=True)
    (act): GELU()
    (fc2): Linear(in_features=3072, out_features=768, bias=True)
    (drop): Dropout(p=0.0, inplace=False)
  )
)
Module Name: aux_classifiers.1.aug.0.norm1, Module: LayerNorm((768,), eps=1e-06, elementwise_affine=True)
Module Name: aux_classifiers.1.aug.0.attn, Module: Attention(
  (qkv): Linear(in_features=768, out_features=2304, bias=True)
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=768, out_features=768, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
Module Name: aux_classifiers.1.aug.0.attn.qkv, Module: Linear(in_features=768, out_features=2304, bias=True)
Module Name: aux_classifiers.1.aug.0.attn.attn_drop, Module: Dropout(p=0.0, inplace=False)
Module Name: aux_classifiers.1.aug.0.attn.proj, Module: Linear(in_features=768, out_features=768, bias=True)
Module Name: aux_classifiers.1.aug.0.attn.proj_drop, Module: Dropout(p=0.0, inplace=False)
Module Name: aux_classifiers.1.aug.0.drop_path, Module: Identity()
Module Name: aux_classifiers.1.aug.0.norm2, Module: LayerNorm((768,), eps=1e-06, elementwise_affine=True)
Module Name: aux_classifiers.1.aug.0.mlp, Module: Mlp(
  (fc1): Linear(in_features=768, out_features=3072, bias=True)
  (act): GELU()
  (fc2): Linear(in_features=3072, out_features=768, bias=True)
  (drop): Dropout(p=0.0, inplace=False)
)
Module Name: aux_classifiers.1.aug.0.mlp.fc1, Module: Linear(in_features=768, out_features=3072, bias=True)
Module Name: aux_classifiers.1.aug.0.mlp.act, Module: GELU()
Module Name: aux_classifiers.1.aug.0.mlp.fc2, Module: Linear(in_features=3072, out_features=768, bias=True)
Module Name: aux_classifiers.1.aug.0.mlp.drop, Module: Dropout(p=0.0, inplace=False)
Module Name: aux_classifiers.1.aug.1, Module: Block(
  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=768, out_features=2304, bias=True)
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=768, out_features=768, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (drop_path): Identity()
  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=768, out_features=3072, bias=True)
    (act): GELU()
    (fc2): Linear(in_features=3072, out_features=768, bias=True)
    (drop): Dropout(p=0.0, inplace=False)
  )
)
Module Name: aux_classifiers.1.aug.1.norm1, Module: LayerNorm((768,), eps=1e-06, elementwise_affine=True)
Module Name: aux_classifiers.1.aug.1.attn, Module: Attention(
  (qkv): Linear(in_features=768, out_features=2304, bias=True)
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=768, out_features=768, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
Module Name: aux_classifiers.1.aug.1.attn.qkv, Module: Linear(in_features=768, out_features=2304, bias=True)
Module Name: aux_classifiers.1.aug.1.attn.attn_drop, Module: Dropout(p=0.0, inplace=False)
Module Name: aux_classifiers.1.aug.1.attn.proj, Module: Linear(in_features=768, out_features=768, bias=True)
Module Name: aux_classifiers.1.aug.1.attn.proj_drop, Module: Dropout(p=0.0, inplace=False)
Module Name: aux_classifiers.1.aug.1.drop_path, Module: Identity()
Module Name: aux_classifiers.1.aug.1.norm2, Module: LayerNorm((768,), eps=1e-06, elementwise_affine=True)
Module Name: aux_classifiers.1.aug.1.mlp, Module: Mlp(
  (fc1): Linear(in_features=768, out_features=3072, bias=True)
  (act): GELU()
  (fc2): Linear(in_features=3072, out_features=768, bias=True)
  (drop): Dropout(p=0.0, inplace=False)
)
Module Name: aux_classifiers.1.aug.1.mlp.fc1, Module: Linear(in_features=768, out_features=3072, bias=True)
Module Name: aux_classifiers.1.aug.1.mlp.act, Module: GELU()
Module Name: aux_classifiers.1.aug.1.mlp.fc2, Module: Linear(in_features=3072, out_features=768, bias=True)
Module Name: aux_classifiers.1.aug.1.mlp.drop, Module: Dropout(p=0.0, inplace=False)
Module Name: aux_classifiers.1.loss_function, Module: CrossEntropyLoss()
Module Name: aux_classifiers.1.head, Module: Linear(in_features=768, out_features=10, bias=True)
Module Name: aux_classifiers.1.norm, Module: LayerNorm((768,), eps=1e-06, elementwise_affine=True)
Module Name: aux_classifiers.1.pre_logits, Module: Identity()
Module Name: norm, Module: LayerNorm((768,), eps=1e-06, elementwise_affine=True)
Module Name: pre_logits, Module: Identity()
Module Name: head, Module: Linear(in_features=768, out_features=10, bias=True)
